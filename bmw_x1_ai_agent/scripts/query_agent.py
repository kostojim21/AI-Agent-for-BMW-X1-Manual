import os
import google.generativeai as genai
from sentence_transformers import SentenceTransformer
import chromadb
import unicodedata
import warnings
import logging
from deep_translator import GoogleTranslator  
import streamlit as st

genai.configure(api_key="AIzaSyCH_aCbyn0NR4BgoKJxXkbkM9uwARI7ZRw")

embedding_model = SentenceTransformer("all-MiniLM-L6-v2")

client = chromadb.PersistentClient(path="output/vector_store")
collection = client.get_collection("bmw_manual")

def call_gemini(prompt):
    try:
        model = genai.GenerativeModel(
            model_name="gemini-2.0-flash",
            generation_config=genai.GenerationConfig(
                temperature=1
            )
        )
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        return f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎºÎ»Î®ÏƒÎ· Gemini: {str(e)} âš ï¸"

def translate_to_english(text):
    return GoogleTranslator(source='auto', target='en').translate(text)

def translate_to_greek(text):
    return GoogleTranslator(source='auto', target='el').translate(text)

def process_question(question, top_k=3):
    try:
        question_en = translate_to_english(question)

        embedding = embedding_model.encode(question_en).tolist()
        results = collection.query(query_embeddings=[embedding], n_results=top_k)

        documents = results['documents'][0]
        metadata = results['metadatas'][0]

        if not documents:
            return "âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ ÏƒÏ‡ÎµÏ„Î¹ÎºÎ® Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î±. âŒ"

        context = ""
        for doc, meta in zip(documents, metadata):
            source = meta.get("source", "Î†Î³Î½Ï‰ÏƒÏ„Î· ÏƒÎµÎ»Î¯Î´Î±")
            context += f"\n[Î Î·Î³Î®: {source}]\n{doc}\n"

        prompt = f"""Answer the following question based on the excerpts from the BMW X1 manual analytically.

Question: {question_en}

Excerpts:
{context}

Answer:"""

        answer_en = call_gemini(prompt)
        return translate_to_greek(answer_en)

    except Exception as e:
        return f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚: {str(e)} âš ï¸"

if __name__ == "__main__":
    st.title("ğŸš— Î’Î¿Î·Î¸ÏŒÏ‚ BMW Manual")
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    if prompt := st.chat_input("What is up?"):
        with st.chat_message("user"):
            st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message(name="assistant", avatar="ğŸ¤–"):
        st.write("Î“ÏÎ¬ÏˆÏ„Îµ Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ® ÏƒÎ±Ï‚ Î® 'exit' Î³Î¹Î± Î­Î¾Î¿Î´Î¿.")
        
    while True:
        question = st.input("â“ Î•ÏÏÏ„Î·ÏƒÎ·: ")
        if question.strip().lower() in ["exit", "quit", "Î­Î¾Î¿Î´Î¿Ï‚"]:
            print("ğŸ‘‹ ÎˆÎ¾Î¿Î´Î¿Ï‚...")
            break
        response = process_question(question)
        st.write("Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·:\n", response)
